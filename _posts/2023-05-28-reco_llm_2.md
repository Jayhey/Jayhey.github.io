---
title: 추천 모델과 LLM - 2
description: ChatGPT와 추천 모델들이 어떤 방식으로 합쳐지고 있을까요? ChatGPT 등장 전 활발하게 연구되던 transformer 기반의 추천 모델들을(P5, M6-Rec) 살펴보겠습니다.
category: Deep Learning
tags:
- NLP
- Recommendation
---



# 추천 모델과 LLM - 2

## Introduction

최근에 ChatGPT가 나오고 나서, 슬슬 거대 생성모델에 추천 시스템을 붙여보는 연구들이 활발하게 진행되고 있는 것 같습니다. 불과 출시한지 반 년 정도밖에 지나지 않았는데도 재미있는 연구들이 몇 가지 나왔는데요, 이번 포스트에서는 2가지 논문에 대해 간단히 적어보려 합니다. 두 논문 모두 ChatGPT 또는 LLaMA 같은 거대 모델들을 사용하여 추천 시스템을 구축하는데 목표를 두었습니다. Fine-tuning 유무에 따른 접근 방식이 다른 것도 상당히 흥미롭습니다.


## TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation

먼저 첫 번째 연구는 LLaMA를 fine-tuning 해서 직접 학습시키는 방법을 사용했습니다. 저자는 LLM 모델들이 엄청나게 성능이 좋아지면서 prompt를 사용한 추천 시도가 상당히 많아졌음에도 불구하고, in-context learning 방식으로는 LLM 모델을 사용한 추천이 잘 먹히지 않는다고 밝히고 있습니다. 따라서 이를 극복하기 위해 추천에서 잘 먹힐 수 있는 새로운 tuning framework를 소개하며 이를 TALLRec이라고 이름을 붙였다고 합니다. 

<div align="center">
<img src="https://i.imgur.com/h080Vwb.png" title="TALLRec" width="700"/>
</div>

연구자들은 위 그림처럼 ChatGPT를 사용해서 in-context learning 방법을 사용하면 생각보다 성능이 잘 나오지 않는다고 밝히고 있습니다. 물론 in-context learning 자체는 P5 처럼 예전 방식들을 잘 사용한다면 성능이 잘 나온다는건 이미 확인된 사실이긴 합니다. 다만 이전보다 더 진보된 새로운 NLP 모델들에 효율적으로 학습시키는 방안을 제안하는게 이 연구의 목적이라고 보시면 될 것 같습니다. 


<div align="center">
<img src="https://i.imgur.com/10ShjCv.png" title="TALLRec" width="700"/>
</div>

학습 핵심 아이디어는 다음 두 가지 진행과정을 차례로 거칩니다.
- Instruction tuning : 모델의 generatlization 성능을 올리기 위한 작업
- Rec tuning : 실제 추천 task를 학습

Instruction tuning이란 "instruction" 개념을 잘 학습할 수 있도록 하는 과정입니다. 
먼저 "task instruction", "task input", "task output"으로 명확하게 해야 할일을 자연어로 정의한 데이터를 준비합니다. 위 그림에서 Instruction Input(Rec Input) 부분에는 task instructino을 넣고, Instruction Output(Rec Output) 부분에는 task output을 넣어 data 쌍을 생성합니다. 이후 만들어진 데이터로 LLM을 fine tuning 하게 됩니다. 

<div align="center">
<img src="https://i.imgur.com/X9utDc2.png" title="TALLRec" width="500"/>
</div>

Rec tuning은 용어만 변경해서 추가 학습을 진행하는 과정입니다. 
(유저의 이전 아이템에 대한 선호도 sequential 데이터로 이루어짐)
- Task instruction → Rec instruction
- Task Input → Rec input
- Task Output → Rec Output
 
 Fine-tuning 과정에서는 학습 효율화를 위해 LoRA architecture를 사용했다고 합니다.


<div align="center">
<img src="https://i.imgur.com/UFhn1VL.png" title="TALLRec" width="700"/>
</div>

영화 추천 데이터, 책 추천 데이터를 사용하여 성능 측정을 진행하였고, LLMs-LLaMA를 fine-tuning하여 few-shot training을 한 결과 상당히 좋은 성능을 보여주고 있습니다. 학습 과정은 nvidia RTX 3090 24GB 한 장으로 진행했다고 하며 [github에 코드도 공개](https://github.com/SAI990323/TALLRec/tree/main/data)하고 있습니다. Cross-domain 관점에서도 일반화에 좋은 성능을 보여주었다는 점이 흥미롭네요.



### Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System

위 연구와는 다르게 이번 논문은 ChatGPT의 Prmopt를 조금 더 잘 활용해보는걸 목적으로 하고 있습니다. 일단 기존 모델의 단점들을 아래와 같이 정리하고 있습니다.
- 기존 추천 시스템에서는 사용자와 모델이 서로 상호작용을 하기 어렵고 추천 결과에 대한 설명이 부족
- Cold-start 문제를 해결할 수 없음
- LLM을 그대로 활용하지 않고 데이터 생성 + fine tuning 작업만 추가하여 새로 모델 구축하는 방법만 사용
ChatGPT가 등장하고나서 사용자와 모델 간 상호작용이 상당히 쉬워졌으니 해당 강점을 살려 위 문제점들을 해결해보겠다는 겁니다.

여기서 제안하는 추천 시스템의 **핵심 특징**을 두 가지로 정리해보면 다음과 같습니다. 
- LLMs-Augmented Recommender System : 기존 추천 시스템의 강점과 대화형 인터페이스 기반의 상호작용, 추천 사유를 설명해주는 LLM의 강점을 합치기
- Without fine-tuning : 특정 backbone 모델의 파라미터 업데이트 없이 사용자/아이템 정보와 텍스트를 prompt로 전달하여 실시간 컨텍스트에 맞게 활용 (in-context learning)

<div align="center">
<img src="https://i.imgur.com/BJQqnin.png" title="ChatREC" width="700"/>
</div>

위 그림은 전체적인 구조입니다. 여기서 input data (prompt)로 들어가는 정보들은 다음과 같습니다.
- user-item history : 사용자와 아이템간 상호작용 정보(여기서는 사용자의 영화 시청 이력)
- user profile : 사용자의 나이, 성별 등 프로파일 정보
- user query : 사용자의 입력 텍스트 (ex. 액션 영화 추천해줘)
- dialogue history : 사용자와 모델 간 대화 기록 (없으면 제외)

그림에 있는 Recommender system은 추천 item candidate set을 반환해줍니다. 반환된 item 정보를 가지고 prompt constructor에서는 input data의 다양한 정보들을 활용하여 prompt를 생성합니다. 작동 프로세스를 정리해보면 아래와 같습니다.

1. Input Data 입력
2. Recommender System을 사용하여 Top K 추천 결과물 반환 (만약 추천 시스템이 필요없다면 그냥 바로 대화로 넘어감)
3. Prompt Constructor 에서 Input Data 와 중간 추천 결과물을 바탕으로 LLM 에 주입될 프롬프트를 자연어 형태로 생성
4. LLM 을 통해 사용자 특성을 반영하여 중간 결과물을 최종 결과물 형태로 ReRank. LLM을 통해 추천 아이템에 대한 추천 사유 추가 제공


<div align="center">
<img src="https://i.imgur.com/Dgt0jSo.png" title="ChatREC" width="700"/>
</div>




논문에서는 MovieLens 100k 데이터셋을 사용하여 Top-5 recommendation & Rating prediction 성능을 측정하였습니다. 두가지 task 모두에서 Chat-REC이 좋은 성능을 보여준다고 합니다.


일단 해당 연구에서 제안하는 방식의 가장 큰 강점은 대화형 인터페이스로 multi-turn 기반 추천이 가능하다는 점 같습니다. 대화 중에서도 사용자의 선호사항을 바로 반영이 가능하며, 취향에 맞게 개인화가 가능합니다. 

<div align="center">
<img src="https://i.imgur.com/Z7VJcS6.png" title="ChatREC" width="700"/>
</div>

그리고 요새 많이 나오는 LLM 활용 프레임워크들을 사용한다면 외부 DB와 연결하는 방식으로 ChatGPT의 단점 중 하나인 최신 정보까지 반영이 가능합니다. Langchain 예제에서도 나오는 방식으로 임베딩 값을 외부 DB에 저장한다면 ChatGPT가 학습하지 못한 2023년 데이터 관련해서도 잘 답변하는걸 볼 수 있습니다. 즉, 새롭게 등장한 아이템이 있더라도 텍스트 임베딩 정보를 사용하여 item-item & user-item 간 유사성 파악이 가능하다는 뜻입니다.

<div align="center">
<img src="https://i.imgur.com/mlkJRCS.png" title="ChatREC" width="700"/>
</div>

또 하나의 강점 중 하나는 도메인간 유사성을 ChatGPT가 이미 잘 파악하고 있기 때문에 cross-domain 관점에서 좋은 성능을 보여준다는 것입니다. 위 그림에서도 유저의 과거 데이터를 활용해서 비디오 게임, 책, 팟캐스트 등 다양한 분야에서 추천 아이템과 추천 사유를 쉽게 제공하는 것이 확인됩니다. 다양한 도메인에서 개인화된 추천이 가능하다는게 매우 큰 강점 중 하나인 것 같습니다.


## 정리하며

ChatGPT의 등장 이후 추천 시스템에서 어떤 방향으로 연구가 진행되고 있는지 살펴봤습니다. 전통적인 fine-tuning  접근 방식을 시도하는 경우도 있고, 추가적인 학습 없이 ChatGPT 하나만 가지고 대화 형식으로 prompt contructor를 통한 추천으로 접근하는 방식 이렇게 크게 두 가지 방향으로 연구가 진행되는 것 같습니다. 

ChatREC을 보면 수많은 자연어를 통해 학습된 거대 언어 모델이 상당히 정교한 방식으로 사용자에게 다양한 도메인에 걸맞는 아이템을 쉽게 추천하는 모습이 보입니다. 추천 쪽도 아마 시간이 흐른다면 하나의 큰 모델을 통해 서로 다른 도메인을 자연스럽게 추천하고 다양한 추천 근거들을 보여줄 수 있는 방향으로 가지 않을까요? 



> Reference
> * [TALLRec: An Effective and Efficient Tuning Framework to Align Large
Language Model with Recommendation](https://arxiv.org/pdf/2305.00447.pdf)
> * [Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System](https://arxiv.org/pdf/2303.14524.pdf)



