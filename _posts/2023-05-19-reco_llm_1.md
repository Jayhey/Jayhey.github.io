---
title: 추천 모델과 LLM - 1
description: ChatGPT와 같은 생성형 LLM들의 성능이 매우 좋아지면서, 추천 모델들이 어떤 방식으로 해당 모델들과 접목되고 있는지 살펴보겠습니다.
category: Deep Learning
tags:
- NLP
- Recommendation
---



# 추천 모델과 LLM - 2

## Introduction

최근 추천 모델들을 리서치 하다가, 상당히 재미있는 연구들이 많아서 공유하고자 합니다. ChatGPT가 생성되면서 여러가지 zero-shot 기반의 추천 방법론들이 상당히 많이 제안되고 있습니다. 사실 현재로선 ChatGPT 수준의 모델을 따로 받아서 추가로 학습할 수는 없는 상황이기 때문에 LLaMA 같이 유출된 모델을 학습시키지 않는 이상 zero-shot 기반의 in-context learning이 아니면 방법이 없긴 합니다. 일단 이번 포스트에서는 전통적인(?) transformer 기반의 추천 모델들을 간단히 소개해보도록 하겠습니다. 


## LLM + Recommendation

### Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)

이름에 paradigm이 들어간 패기를 보여주고 있는 논문입니다. 트랜스포머 기반의 모델들이 성행하던 시절, 어느 정도 인용도 되면서 좋은 성능을 보여주는 모델이라고 할 수 있습니다. 논문에서는 LLM 모델들이 엄청 거대해지면서 다양한 zero-shot task들에 사용 되고 있기 때문에 다양한 추천 task들을 하나의 LLM에서 추론할 수 있게 학습해보자 했다고 합니다.
이때 당시만 해도 hugging face에 최신 모델들이 모두들 공유하던 분위기였던 만큼, 해당 논문에서는 T5 모델을 기반으로 추천 모델을 학습했습니다.


<div align="center">
<img src="https://i.imgur.com/yKZ7eTj.png" title="p5" width="700"/>
</div>

```
# 예시 데이터
Input: "I find the purchase history list of user_15466:
4110 -> 4467 -> 4468 -> 4472
I wonder what is the next item to recommend to the user. Can you help
me decide?"
Output: "1581"
```

일단 추천 관련 raw data를 아래 5개의 task로 분리하였습니다. 위 그림은 다양한 raw data를 어떤 방식으로 나누었는지 보여주는 예시입니다.
- Rating : item rating (1~5 score) / 선호 여부
- Sequential recommendation : item interaction history를 가지고 다음 아이템 예측
- Explanation : 주어진 item에 대한 유저의 선호를 텍스트로 생성
- Review : 상품에 대한 코멘트 요약 / 리뷰 코멘트를 가지고 점수 예측
- Direct recommendation : 유저에게 item을 직접적으로 추천 / 아이템 목록에서 유저에게 맞는 아이템 추천

5개로 나눈 task를 각자의 모델에 따로 학습하는게 아니라, T5 base 모델에 학습을 시켰습니다.


<div align="center">
<img src="https://i.imgur.com/1LjNyBq.png" title="p5" width="700"/>
</div>

쉽게 이야기하면, 다양한 추천 관련 NLP raw data를 5개의 task에 맞춰 나눠서 하나의 T5 모델을 기반으로 학습시켰습니다. 어떻게 보면 참신한 모델을 사용한 것도 아니고, 거대 언어 모델 base를 하나 잡아서 데이터만 추천 task에 맞게 변형한 상황입니다.


<div align="center">
<img src="https://i.imgur.com/wv4jr85.png" title="p5" width="700"/>
</div>

예시로 두 가지 task에 대한 성능만 가져오긴 했지만, P5가 전체적으로 좋은 성능을 보여주고 있음을 확인할 수 있습니다. (개인적으로는 루지스코어를 이용하는게 맞나? 싶은 생각도 들긴 했는데...) 일단 LLM 모델을 추천 task에 맞게 학습시켜도 좋은 성능이 나올 수 있음을 보여주는데 의의가 있는 것 같습니다. 다양한 추천 task를 하나의 모델에서 처리하는 관점에서 여타 논문들 중 신뢰도가 높은 편에 속하고 학습하는데도 큰 자원이 필요하지 않다는 점은 장점으로 보입니다. (nvidia ax5000 x 4 기준 작은 모델은 6.7시간, base모델은 24.3시간)

다만 현재 핫한 생성 모델과 비교했을 때 백본 모델인 T5 자체의 성능이 조금 아쉽다는 생각이 들기도 합니다. Explanation 같은 task에서는 ChatGPT가 훨씬 잘할 것 같네요. 특히 Generalization 관점에서 본 적이 없는 prompt나 item 대상으로는 과연 어느정도 더 좋은 성능이 나올지 의문이 들기도 합니다.

### M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender System

두 번째 논문은 M6-Rec 입니다. 이 논문에서는 서론에서 기존의 추천 시스템의 한계를 다음과 같이 정의하고 있습니다.
- 일반적으로 추천 모델에서는 유저의 행동 데이터만 가지고 추천에 활용하므로 외부 정보 (non-behavior web data) 활용 불가
- item id를 기준으로 학습하므로 새로운 아이템에 대한 추천이 불가능함
- 주로 user X item rating을 추출하는 scoring 혹은 CTR prediction 등에 초점이 맞추어져 있음. 이는 대화 방식의 설명이 필요한 추천에서는 사용이 불가능
- 각 도메인별로 특정 task에 필요한 모델이 각자 필요

정리하자면 NLP 분야에서 이미 pretrain 된 모델들을 추가 학습해서 특정 도메인의 task를 더 잘 할수 있는 모델을 만드는 방식을 굉장히 많이 사용하고 있으니 추천에서도 이런 방식을 사용해보자는 겁니다. Pretrain 된 하나의 big one 추천 모델이 있다면 좋겠다는 뜻이죠. 

일단 핵심 아이디어는 아래와 같습니다.

> 기존의 추천 로그를 언어 모델에서 이용할 수 있는 방식으로 변환 후 통합 추천 모델을 효율적으로 학습하기 위한 방법 개발

기존 NLP 모델들처럼 fine tuning만 하게 되면 데이터 labeling 작업도 필요하고, 이전 학습된 데이터도 잊어버리는 문제도 생기기 때문에 범용 모델이 되는데는 한계가 있다고 합니다. 따라서 논문에서는 prompt-tuning으로 이를 해결하고자 합니다.
모델의 파라미터를 고정하고, 각 task에 대한 prompt만 만들고 mixed 배치로 넣어가면서 encoding 하면 LLM 모델은 건드리지 않더라도 여러 개의 모델이 생기게 됩니다.


<div align="center">
<img src="https://i.imgur.com/RawFT1y.png" title="m6-rec" width="700"/>
</div>

이렇게 할 경우 converge 속도가 느려지는 문제가 생기게 되므로, 위 이미지의 Option tuning 이란 방법을 사용하여 속도를 높이고 있습니다. Prompt embedding에 사용되는 shared weight을 사용해서 학습 속도를 높이는 겁니다.


<div align="center">
<img src="https://i.imgur.com/BntGuTT.png" title="m6-rec" width="700"/>
</div>


또한 inference 속도가 상당히 느리다는 단점이 있으므로 이를 개선하기 위해 위 이미지처럼 L' 레이어 전까지는 cache 된 세그먼트 결과를 활용하고 L-L' 부분만 계산하고 있습니다.

<div align="center">
<img src="https://i.imgur.com/t5QxzPw.png" title="m6-rec" width="700"/>
</div>

전체적으로 다양한 task(Scoring - CTR, CVR, Generation-explanation, personalized product design, search query, Retrieval)에서 상당히 우수한 성능을 보여주고 있습니다.

논문에서 제안하는 모델의 특징을 정리해보자면, 공통 모델을 기준으로 다양한 추천 task를 한번에 수행할 수 있다는 강점이 있습니다. 그리고 cache 값을 사용하는 방식으로 inference 속도를 빠르게 했으며 user-item 최신 history 정보까지 반영이 가능합니다. 또한 아예 학습에 사용되지 않은 아이템까지도 추천할 수가 있습니다.

## 정리하며

일단 ChatGPT의 등장 전에 연구되고 있던 transformer 기반의 추천 모델들에 대해 알아봤습니다. 확실히 collaborative filtering 등 전통적인 머신러닝 방법론들과는 다르게 pretrained NLP 모델 같은걸 만들고자 하는 목적의식이 분명한 것 같습니다. 
실제 사용사례를 찾아보고자 했는데 사실 찾아보기가 쉽지 않았습니다. Cold start 문제 등 추천쪽에서 고질적으로 풀기 어려웠던 문제들을 쉽게 풀어낼 수 있는게 장점인 것 것으로 보입니다. 알리바바 처럼 같이 다양한 상품들을 취급하는 회사의 지원을 받아 작성된 논문인 만큼 다른 곳에서도 사용하는지 사용 사례를 찾아보았지만 찾기가 어려운게 조금 아쉬웠습니다.  

 다음 포스트에서는 ChatGPT의 등장 이후 transformer 기반 모델들의 연구 방향이 어떤 방식으로 변경되었는지 알아보고자 합니다. 


> Reference
> * [Recommendation as Language Processing (RLP):
A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)](https://arxiv.org/pdf/2203.13366.pdf)
> * [M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender System](https://arxiv.org/abs/2205.08084)



